{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Bike Rental Forecasting using LSTM based Network #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "import datetime\n",
    "import random\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, TimeDistributed\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "import pandas as pd\n",
    "from keras import optimizers\n",
    "import datetime\n",
    "\n",
    "slidingwindow = 12\n",
    "maxval_w = 1\n",
    "maxval_pb = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Data Preparation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parse_data(df, window_sz):\n",
    "    data = np.squeeze(np.reshape(df, newshape= [-1,1]), axis=1)\n",
    "    \n",
    "    init = np.zeros(window_sz)\n",
    "    result=[]\n",
    "    data = np.append(init,data)\n",
    "    #print(data[0:34])\n",
    "    \n",
    "    for index in range(window_sz,len(data)):\n",
    "        tmp=[]\n",
    "        tmp = data[index-window_sz:index]\n",
    "        #tmp = data[2:14]\n",
    "        rsed_arr = tmp[::-1]\n",
    "        #result.append(np.append([data[index]],tmp))\n",
    "        result.append(rsed_arr)\n",
    "    result=np.array(result)\n",
    "    print(result.shape)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def load_data(fname):\n",
    "    global noballs, slidingwindow, norm_wndw\n",
    "    print(\"*** loading data ***\")\n",
    "    df = pd.read_csv(fname)\n",
    "\n",
    "    data = np.array(df.iloc[:, 12])\n",
    "    \n",
    "    trainX = parse_data(data, slidingwindow)\n",
    "    df = np.concatenate((trainX,df), axis=1)\n",
    "\n",
    "    print(\"Data has size of \", data.shape)\n",
    "    print(\"Sample data on how lag features look for the forecast:\\n\",trainX[0:20:,])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** loading data ***\n",
      "(17379, 12)\n",
      "Data has size of  (17379,)\n",
      "Sample data on how lag features look for the forecast:\n",
      " [[   0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  16.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  40.   16.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  32.   40.   16.    0.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [  13.   32.   40.   16.    0.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   1.   13.   32.   40.   16.    0.    0.    0.    0.    0.    0.    0.]\n",
      " [   1.    1.   13.   32.   40.   16.    0.    0.    0.    0.    0.    0.]\n",
      " [   2.    1.    1.   13.   32.   40.   16.    0.    0.    0.    0.    0.]\n",
      " [   3.    2.    1.    1.   13.   32.   40.   16.    0.    0.    0.    0.]\n",
      " [   8.    3.    2.    1.    1.   13.   32.   40.   16.    0.    0.    0.]\n",
      " [  14.    8.    3.    2.    1.    1.   13.   32.   40.   16.    0.    0.]\n",
      " [  36.   14.    8.    3.    2.    1.    1.   13.   32.   40.   16.    0.]\n",
      " [  56.   36.   14.    8.    3.    2.    1.    1.   13.   32.   40.   16.]\n",
      " [  84.   56.   36.   14.    8.    3.    2.    1.    1.   13.   32.   40.]\n",
      " [  94.   84.   56.   36.   14.    8.    3.    2.    1.    1.   13.   32.]\n",
      " [ 106.   94.   84.   56.   36.   14.    8.    3.    2.    1.    1.   13.]\n",
      " [ 110.  106.   94.   84.   56.   36.   14.    8.    3.    2.    1.    1.]\n",
      " [  93.  110.  106.   94.   84.   56.   36.   14.    8.    3.    2.    1.]\n",
      " [  67.   93.  110.  106.   94.   84.   56.   36.   14.    8.    3.    2.]\n",
      " [  35.   67.   93.  110.  106.   94.   84.   56.   36.   14.    8.    3.]]\n"
     ]
    }
   ],
   "source": [
    "preppeddata=load_data(\"Regression_ Demand estimation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def createDataset(df):\n",
    "    row = int(0.89971*df.shape[0])\n",
    "    traindf = df[0:row,:]\n",
    "    testdf = df[row:,:]\n",
    "    trainY=traindf[:,-1]\n",
    "    trainX=traindf[:,:-1]\n",
    "    testY = testdf[:,-1]\n",
    "    testX = testdf[:,:-1]\n",
    "    return trainX, trainY, testX, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "trX, trY, tsX, tsY = createDataset(preppeddata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train X shape (15636, 24)\n",
      "train Y shape (15636,)\n",
      "test X shape (1743, 24)\n",
      "test Y shape (1743,)\n"
     ]
    }
   ],
   "source": [
    "print(\"train X shape\", trX.shape)\n",
    "print(\"train Y shape\", trY.shape)\n",
    "print(\"test X shape\", tsX.shape)\n",
    "print(\"test Y shape\", tsY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def hyper_parameters(window_sz):\n",
    "    global units, dropouts, layers, outputunits, input_dim, batch_sz, numepochs\n",
    "    unitset  = [96, 96, 96, 96]\n",
    "    layerset = [1, 1, 1, 1, 1]\n",
    "    dropoutset = [0.4,0.4,0.4]\n",
    "    \n",
    "    layers = random.choice(layerset)\n",
    "    units = np.zeros(layers)\n",
    "    dropouts = np.zeros(layers)\n",
    "    batch_sz = 96\n",
    "    for i in range(0, layers):\n",
    "        units[i] = random.choice(unitset)\n",
    "        dropouts[i] = random.choice(dropoutset)\n",
    "    units[0] = batch_sz\n",
    "    \n",
    "    outputunits = 1\n",
    "    \n",
    "    numepochs = 10\n",
    "    \n",
    "    print(layers)\n",
    "    print(units)\n",
    "    print(dropouts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Try creating network without dropouts. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def setupNetwork(window_sz):\n",
    "    global units, dropouts, layers, outputunits\n",
    "    model = Sequential()\n",
    "\n",
    "    timestamps = 1\n",
    "    features = 24\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=units[0].astype(\"int64\"), return_sequences=False, input_shape=(features, timestamps)))\n",
    "    #model.add(Dropout(dropouts[0]))\n",
    "    model.add(Dense(units=batch_sz*2))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(timestamps))\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[ 96.]\n",
      "[ 0.4]\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 96)                37632     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 192)               18624     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 192)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 193       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 56,449\n",
      "Trainable params: 56,449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "hyper_parameters(slidingwindow)\n",
    "model = setupNetwork(slidingwindow)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def trainModel(m, xtr, ytr, ep, bsz,l=0):\n",
    "    \n",
    "\n",
    "    m.fit(xtr, ytr, batch_size=bsz, epochs=ep, validation_split=0.079, verbose=l)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "Train on 14400 samples, validate on 1236 samples\n",
      "Epoch 1/1\n",
      "6s - loss: 33261.0362 - val_loss: 48652.8404\n"
     ]
    }
   ],
   "source": [
    "global batch_sz\n",
    "print(batch_sz)\n",
    "modelrest = trainModel(model, trX.reshape(-1,24,1), trY.reshape(-1,1), 1, batch_sz,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Model Evaluation ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def compute_perf(m, xts, yts):\n",
    "    ypred = m.predict(xts.reshape(xts.shape[0],24,-1))\n",
    "    py = np.squeeze(np.reshape(ypred, newshape= [-1,1]), axis=1)\n",
    "    r2 = mt.r2_score(yts, ypred)\n",
    "    #print(r2)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Run parameter sweep across batch and epoch to find the best parameters that give best R^2 value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def parameter_sweep():\n",
    "    marr = np.empty((8,5), dtype=Sequential)\n",
    "    r2 = np.zeros((8,5))\n",
    "    rowcnt = 0\n",
    "    colcnt = 0\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"|     R^2    |            epochs                     |\")\n",
    "    print(\"------------------------------------------------------\")\n",
    "    print(\"| batch size | \",end=\"\")\n",
    "    for e in range(2,12,2):\n",
    "        print(\" %3d  | \"% e, end=\"\")\n",
    "    print()\n",
    "    print(\"------------------------------------------------------\")\n",
    "    for b in range(24,192,24):\n",
    "        colcnt = 0\n",
    "        print(\"|   %3d      |\"% b, end=\"\")\n",
    "        for e in range(2,12,2):\n",
    "            mtmp = setupNetwork(slidingwindow)\n",
    "            marr[rowcnt, colcnt] = trainModel(mtmp, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "            r2[rowcnt, colcnt] = compute_perf(marr[rowcnt, colcnt], tsX, tsY)\n",
    "            \n",
    "            r = r2[rowcnt, colcnt]\n",
    "            print(\" %0.4f|\"% r,end=\"\")\n",
    "            colcnt += 1\n",
    "            #print(\"batch size = \", b, \" epochs = \", e, \" r^2 = \", r2[rowcnt, colcnt])\n",
    "        rowcnt +=1\n",
    "        print()\n",
    "    print(\"------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "The comparable data using 12 lag features when trained on Azure ML v1 using Boosted decision tree gives R-Square value of 0.82. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Running parameter sweep across various batch sizes and epochs taks almost 30 mins on 1 GPU based VM. So only run the cell below if you have 30 mins. Else use the data from my run as shown below which shows that batch size with 48 for 10 epochs gives the best result of R^2 being **0.8936** or use 24 batch size with 6 epochs for decent R^2 of **0.8711**. \n",
    "\n",
    "![](http://neerajkh.blob.core.windows.net/images/parametersweep_bikerental.PNG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of parameter sweep: 2017-08-17 06:58:03.419863\n",
      "------------------------------------------------------\n",
      "|     R^2    |            epochs                     |\n",
      "------------------------------------------------------\n",
      "| batch size |    2  |    4  |    6  |    8  |   10  | \n",
      "------------------------------------------------------\n",
      "|    24      | 0.7883| 0.8528| 0.8711| 0.8650| 0.8869|\n",
      "|    48      | 0.7416| 0.8680| 0.8608| 0.8122| 0.8936|\n",
      "|    72      | 0.5781| 0.7339| 0.8339| 0.8421| 0.8768|\n",
      "|    96      | 0.4999| 0.8006| 0.8537| 0.8328| 0.8344|\n",
      "|   120      | 0.5199| 0.7757| 0.6741| 0.8744| 0.8855|\n",
      "|   144      | 0.5152| 0.5872| 0.8151| 0.7679| 0.8827|\n",
      "|   168      | 0.4721| 0.4786| 0.7987| 0.5265| 0.8289|\n",
      "------------------------------------------------------\n",
      "end of parameter sweep: 2017-08-17 07:28:01.795318\n",
      "total time =  0:29:58.375455\n"
     ]
    }
   ],
   "source": [
    "start = datetime.datetime.now()\n",
    "print(\"start of parameter sweep:\", start)\n",
    "#parameter_sweep()\n",
    "end = datetime.datetime.now()\n",
    "print(\"end of parameter sweep:\", end)\n",
    "print(\"total time = \", end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Running parameter sweep also provided hint that we can combine various batch sizes and epochs to get the best results. Here is the one way to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def trainWithVaryingBatchAndEpochs(m):\n",
    "    \n",
    "    b = 24\n",
    "    for e in range(2,8,2):      \n",
    "        m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "        r2 = compute_perf(m, tsX, tsY)\n",
    "        print(\"At end of epoch %d \"% e, end=\"\")\n",
    "        print(\"using batch size of %d \"% b, end=\"\")\n",
    "        print(\"the r^2 is %0.4f|\"% r2)\n",
    "    b = 48\n",
    "    e = 2\n",
    "    m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "    print(\"At end of epoch %d \"% e, end=\"\")\n",
    "    print(\"using batch size of %d \"% b, end=\"\")\n",
    "    print(\"the r^2 is %0.4f|\"% r2)\n",
    "    e = 4\n",
    "    m = trainModel(m, trX.reshape(-1,24,1), trY.reshape(-1,1), e, b, 0)\n",
    "    print(\"At end of epoch %d \"% e, end=\"\")\n",
    "    print(\"using batch size of %d \"% b, end=\"\")\n",
    "    print(\"the r^2 is %0.4f|\"% r2)\n",
    "    return m\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "mtmp = setupNetwork(slidingwindow)\n",
    "#mtmp = trainWithVaryingBatchAndEpochs(mtmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we can try to see if dropouts improve accuracy or not. So we will add dropouts with above configuration and try the new network with dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def setupNetworkWithDropouts(window_sz):\n",
    "    global units, dropouts, layers, outputunits\n",
    "    model = Sequential()\n",
    "\n",
    "    timestamps = 1\n",
    "    features = 24\n",
    "\n",
    "    model.add(keras.layers.LSTM(units=units[0].astype(\"int64\"), return_sequences=False, input_shape=(features, timestamps)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units=batch_sz*2, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(timestamps, activation='linear'))\n",
    "    \n",
    "\n",
    "    model.compile(loss='mse', optimizer='rmsprop')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At end of epoch 2 using batch size of 24 the r^2 is 0.8170|\n",
      "At end of epoch 4 using batch size of 24 the r^2 is 0.8628|\n",
      "At end of epoch 6 using batch size of 24 the r^2 is 0.8045|\n",
      "At end of epoch 2 using batch size of 48 the r^2 is 0.8045|\n",
      "At end of epoch 4 using batch size of 48 the r^2 is 0.8045|\n"
     ]
    }
   ],
   "source": [
    "anothermodel = setupNetworkWithDropouts(slidingwindow)\n",
    "anothermodel = trainWithVaryingBatchAndEpochs(anothermodel) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now that we have tried all alternatives, progressive batch/epoch, dropout etc., the simplest model that provides good accuracy is with batch size 48 and epoch 10. So for now, we will go with that model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For now, let's go with batch size of 48 and 10 epochs with no dropouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14400 samples, validate on 1236 samples\n",
      "Epoch 1/10\n",
      "10s - loss: 2867.1916 - val_loss: 4776.4148\n",
      "Epoch 2/10\n",
      "10s - loss: 2707.0263 - val_loss: 5978.1012\n",
      "Epoch 3/10\n",
      "10s - loss: 2546.9158 - val_loss: 6757.7123\n",
      "Epoch 4/10\n",
      "10s - loss: 2465.9893 - val_loss: 5897.2418\n",
      "Epoch 5/10\n",
      "9s - loss: 2421.4319 - val_loss: 5742.7474\n",
      "Epoch 6/10\n",
      "10s - loss: 2374.0229 - val_loss: 6649.3893\n",
      "Epoch 7/10\n",
      "9s - loss: 2264.1990 - val_loss: 9086.7461\n",
      "Epoch 8/10\n",
      "10s - loss: 2249.5384 - val_loss: 6196.7814\n",
      "Epoch 9/10\n",
      "10s - loss: 2191.3645 - val_loss: 5604.7572\n",
      "Epoch 10/10\n",
      "9s - loss: 2101.7306 - val_loss: 4273.9195\n"
     ]
    }
   ],
   "source": [
    "finalmodel = setupNetwork(slidingwindow)\n",
    "finalmodel = trainModel(model, trX.reshape(-1,24,1), trY.reshape(-1,1), 10, 48,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 =  0.892330549527\n"
     ]
    }
   ],
   "source": [
    "print(\"R^2 = \", compute_perf(finalmodel, tsX, tsY))\n",
    "finalmodel.save(\"finalmodel.sav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Operationalization ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Check for existing **scoring file** and if it exist, remove the scoring file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score file already exist, removing score file\n"
     ]
    }
   ],
   "source": [
    "# remove previous bikescore.py\n",
    "export_path_base = \"bikescore.py\"\n",
    "import os\n",
    "if os.path.exists(export_path_base):\n",
    "    print(\"score file already exist, removing score file\")\n",
    "    os.remove(export_path_base)\n",
    "else:\n",
    "    print(\"no score file found - safe to continue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Write init() and run() functions to score.py file using magic commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting bikescore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile bikescore.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, LSTM, TimeDistributed\n",
    "import pandas as pd\n",
    "\n",
    "def init():\n",
    "    global trainedmod\n",
    "    from keras.models import load_model\n",
    "    \n",
    "    trainedmod = load_model(\"finalmodel.sav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to bikescore.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a bikescore.py\n",
    "\n",
    "def run(npa):\n",
    "    global trainedmod\n",
    "    \n",
    "    if (len(npa.shape) > 1):\n",
    "        ypred = trainedmod.predict(npa.reshape(npa.shape[0],24,1))\n",
    "    else:\n",
    "        ypred = trainedmod.predict(npa.reshape(1,24,1))\n",
    "    retdf = pd.DataFrame(data={\"Scored Values\":np.squeeze(np.reshape(ypred, newshape= [-1,1]), axis=1)})\n",
    "    return str(retdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def testsavedmodel():\n",
    "    global trainedmod\n",
    "    print(\"R^2 = \", compute_perf(finalmodel, tsX, tsY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 =  0.892330549527\n"
     ]
    }
   ],
   "source": [
    "import bikescore\n",
    "bikescore.init()\n",
    "testsavedmodel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Now we have verified that we have loaded correct model as R^2 value of model saved above is same as the model loaded from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  8.90000000e+02   4.50000000e+02   3.53000000e+02   2.85000000e+02\n",
      "   3.32000000e+02   3.77000000e+02   2.68000000e+02   2.18000000e+02\n",
      "   3.87000000e+02   8.34000000e+02   5.08000000e+02   1.53000000e+02\n",
      "   4.00000000e+00   1.00000000e+00   1.00000000e+01   1.80000000e+01\n",
      "   0.00000000e+00   4.00000000e+00   1.00000000e+00   2.00000000e+00\n",
      "   5.60000000e-01   5.30300000e-01   6.40000000e-01   3.28400000e-01]\n"
     ]
    }
   ],
   "source": [
    "print(tsX[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predY = bikescore.run(tsX[0:5,:])\n",
    "trueY=str(pd.DataFrame(data={\"Actual Values\":np.squeeze(np.reshape(tsY[0:5], newshape= [-1,1]), axis=1)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scored Values \t\t\t Actual Values\n",
      "0     818.072937 \t\t\t 0          890.0\n",
      "1     853.520874 \t\t\t 1          788.0\n",
      "2     559.912903 \t\t\t 2          513.0\n",
      "3     451.836731 \t\t\t 3          387.0\n",
      "4     266.931793 \t\t\t 4          283.0\n"
     ]
    }
   ],
   "source": [
    "for x,y in zip(predY.split('\\n'),trueY.split('\\n')):\n",
    "    print(x.strip(), \"\\t\\t\\t\",y.strip()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Generate schema file ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from azure.ml.api.schema.dataTypes import DataTypes\n",
    "from azure.ml.api.schema.sampleDefinition import SampleDefinition\n",
    "import azure.ml.api.realtime.services as amlo16n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'main.py'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"npa\": SampleDefinition(DataTypes.NUMPY, tsX[0:3,:])}\n",
    "amlo16n.generate_schema(inputs=inputs,\n",
    "                            filepath=\"bikeschema.json\",\n",
    "                            run_func=bikescore.run)\n",
    "amlo16n.generate_main(user_file=\"bikescore.py\", schema_file=\"bikeschema.json\",\n",
    "                          main_file_name=\"main.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# check score.py and main.py\n",
    "%pycat bikescore.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%pycat main.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment ##\n",
    "For cluster deployment, you need to setup you environment with ACS, storage, ACR, AppInsights etc. Cluster deployment expects that you have precreated experimentation and model management account through Ibiza as per instructions in the [Instruction Guide](https://github.com/Azure/ViennaDocs/blob/master/Documentation/Installation.md)\n",
    "\n",
    "You can validate your account using the command shown below\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\VIenna\\BikeForecastNotebook>az ml account modelmanagement list\n",
    "{\n",
    "  \"created_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"description\": \"\",\n",
    "  \"id\": \"/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlviennagrp2/providers/Microsoft.MachineLearningModelManagement/accounts/neerajteam2hosting\",\n",
    "  \"location\": \"eastus2\",\n",
    "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlviennagrp2/accounts/neerajteam2hosting/swagger.json?api-version=2017-09-01-preview\",\n",
    "  \"modified_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"name\": \"neerajteam2hosting\",\n",
    "  \"resource_group\": \"amlviennagrp2\",\n",
    "  \"sku\": {\n",
    "    \"capacity\": 1,\n",
    "    \"name\": \"S1\"\n",
    "  },\n",
    "  \"subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\",\n",
    "  \"tags\": null,\n",
    "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\n",
    "}\n",
    "```\n",
    "\n",
    "Let's set this account to be the default account for registering models and web services.\n",
    "\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\VIenna\\BikeForecastNotebook>az ml account modelmanagement set -n neerajteam2hosting -g amlviennagrp2\n",
    "{\n",
    "  \"created_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"description\": \"\",\n",
    "  \"id\": \"/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlviennagrp2/providers/Microsoft.MachineLearningModelManagement/accounts/neerajteam2hosting\",\n",
    "  \"location\": \"eastus2\",\n",
    "  \"model_management_swagger_location\": \"https://eastus2.modelmanagement.azureml.net/api/subscriptions/6d976e3d-6278-4645-ab79-cc5f5fe01a49/resourceGroups/amlviennagrp2/accounts/neerajteam2hosting/swagger.json?api-version=2017-09-01-preview\",\n",
    "  \"modified_on\": \"2017-08-22T02:34:00.837873Z\",\n",
    "  \"name\": \"neerajteam2hosting\",\n",
    "  \"resource_group\": \"amlviennagrp2\",\n",
    "  \"sku\": {\n",
    "    \"capacity\": 1,\n",
    "    \"name\": \"S1\"\n",
    "  },\n",
    "  \"subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\",\n",
    "  \"tags\": null,\n",
    "  \"type\": \"Microsoft.MachineLearningModelManagement/accounts\"\n",
    "}\n",
    "```\n",
    "\n",
    "Once model management account is created, the next step is to create an environment. Users can create K8 based ACS cluster environment using the following commands.\n",
    "\n",
    "Let's validate if our environment has been created and if so, then let's set it to be the default environment for our implementation.\n",
    "```\n",
    "C:\\Users\\neerajkh\\Documents\\VIenna\\BikeForecastNotebook>az ml env setup -n amlviennacluster -c -l eastus2 -g amlviennagrp2\n",
    "Subscription set to Channels\n",
    "Continue with this subscription (Y/n)? Y\n",
    "Resource group amlviennagrp2 already exists, skipping creation.\n",
    "waiting for AAD role to propagate.done\n",
    "Provisioning compute resources...\n",
    "Resource creation submitted successfully.\n",
    "Resources may take 10-20 minutes to be completely provisioned.\n",
    "To see if your environment is ready to use, run:\n",
    "  az ml env show -g amlviennagrp2 -n amlviennacluster\n",
    "Once your environment has successfully provisioned, you can set it as your target context using:\n",
    "  az ml env set -g amlviennagrp2 -n amlviennacluster\n",
    "C:\\Users\\neerajkh\\Documents\\VIenna\\BikeForecastNotebook>az ml env list\n",
    "[\n",
    "  {\n",
    "    \"Cluster Name\": \"amlviennacluster\",\n",
    "    \"Cluster Size\": 2,\n",
    "    \"Created On\": \"2017-08-22T04:03:09.147000+00:00\",\n",
    "    \"Location\": \"eastus2\",\n",
    "    \"Provisioning State\": \"Succeeded\",\n",
    "    \"Resource Group\": \"amlviennagrp2\",\n",
    "    \"Subscription\": \"6d976e3d-6278-4645-ab79-cc5f5fe01a49\"\n",
    "  }\n",
    "]\n",
    "C:\\Users\\neerajkh\\Documents\\VIenna\\BikeForecastNotebook>az ml env set -n amlviennacluster -g amlviennagrp2\n",
    "Compute set to amlviennacluster.\n",
    "```\n",
    "\n",
    "You are all set with environment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Create web service ###\n",
    "Now you can create web service by using command az ml service and passing scoring file, schema file, dependencies file, and model file as shown below\n",
    "\n",
    "\n",
    "```\n",
    "neeraj@mygpudsvm:~/notebooks$ az ml service create realtime -f bikescore.py -s bikeschema.json --model-file finalmodel.sav --model-name bikemodel -n bikews -r spark-py -c conda_dependencies.yml -l\n",
    "Creating new driver at /tmp/tmpguctlak4.py\n",
    "Uploading dependencies.\n",
    " bikescore.py\n",
    " finalmodel.sav\n",
    " bikeschema.json\n",
    " /tmp/tmpnls6y0nk/swagger.json\n",
    " /tmp/requirementsn2fm6ktl.txt\n",
    " conda_dependencies.yml\n",
    "Creating docker image..........done.\n",
    "Image available at : wino16nenvacr.azurecr.io/bikews\n",
    "[Local mode] Running docker container.\n",
    "[Local mode] Pulling the image from wino16nenvacr.azurecr.io/bikews. This may take a few minutes, depending on your connection speed...\n",
    "[Local mode] Pulling...........\n",
    "[Local mode] Success.\n",
    "[Local mode] Scoring endpoint: http://127.0.0.1:32789/score\n",
    "[Local mode] Usage: az ml service run realtime -n bikews -d \"!! YOUR DATA HERE !!\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### List web service details ###\n",
    "\n",
    "You can list web service details along with calling pattern by using the following command\n",
    "\n",
    "```\n",
    "neeraj@mygpudsvm:~/notebooks$ az ml service show realtime -n bikews\n",
    "+--------+---------------------------------+-------+----------+----------+-------------+----------+\n",
    "| NAME   | IMAGE                           | CPU   | MEMORY   | STATUS   |   INSTANCES | HEALTH   |\n",
    "|--------+---------------------------------+-------+----------+----------+-------------+----------|\n",
    "| bikews | wino16nenvacr.azurecr.io/bikews | N/A   | N/A      | running  |           1 | N/A      |\n",
    "+--------+---------------------------------+-------+----------+----------+-------------+----------+\n",
    "Usage:\n",
    "  az ml  : az ml service run realtime -n bikews -d \"{\\\"npa\\\": [[450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 42.0, 4.0, 1.0, 10.0, 17.0, 0.0, 4.0, 1.0, 2.0, 0.58, 0.5455, 0.64, 0.3284], [890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 4.0, 1.0, 10.0, 18.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.64, 0.3284], [788.0, 890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 4.0, 1.0, 10.0, 19.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.68, 0.2985]]}\"\n",
    "  curl : curl -X POST -H \"Content-Type:application/json\" --data \"{\\\"npa\\\": [[450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 42.0, 4.0, 1.0, 10.0, 17.0, 0.0, 4.0, 1.0, 2.0, 0.58, 0.5455, 0.64, 0.3284], [890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 4.0, 1.0, 10.0, 18.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.64, 0.3284], [788.0, 890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 4.0, 1.0, 10.0, 19.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.68, 0.2985]]}\" http://127.0.0.1:32789/score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Calling web service ###\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "You can call the web service through az ml or curl. Here is the output by calling web service from az ml CLI\n",
    "\n",
    "```\n",
    "neeraj@mygpudsvm:~/notebooks$  az ml service run realtime -n bikews -d \"{\\\"npa\\\": [[450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 42.0, 4.0, 1.0, 10.0, 17.0, 0.0, 4.0, 1.0, 2.0, 0.58, 0.5455, 0.64, 0.3284], [890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 153.0, 4.0, 1.0, 10.0, 18.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.64, 0.3284], [788.0, 890.0, 450.0, 353.0, 285.0, 332.0, 377.0, 268.0, 218.0, 387.0, 834.0, 508.0, 4.0, 1.0, 10.0, 19.0, 0.0, 4.0, 1.0, 2.0, 0.56, 0.5303, 0.68, 0.2985]]}\"\n",
    "\n",
    "   Scored Values\n",
    "0     778.923218\n",
    "1     804.909363\n",
    "2     527.499268\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
